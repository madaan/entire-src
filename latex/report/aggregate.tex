\chapter{Distributional Statistics of Named entities}
Once you have a catalog of things, it makes sense to ask which of these ``things'' are more important than the others.
In fact, one might extend the question and ask, ``Which pairs (or triples) of these things appear together on the open web?''.
We define several different statistics one might be interested in over these entity catalogs, discuss some applications, 
propose a baseline method and finally, prepare the ground for the next chapter by giving an outline of a solution 
which is aimed at directly providing us with the statistics we are looking for. 

\section{What Statistics?}

\subsection{Which sense dominates for an entity?}
For starters, we might want to calculate the number of times a particular ``sense'' of an entity\footnote{Please note that we 
refer to entity in general terms. For example, any object having a YAGO id is an entity}. 
For example, the ``Gingerbread'' might refer to several different concepts; from perhaps the most famous Android 2.3 to the novel.
We want to know out of all the \emph{Gingerbreads} on the web, how many refer to the Operating system. 
We call this number the sense prior.
\begin{equation}
\tag{1}
\text{Sense Prior}(S_i, E) =  P(E\text{ appears as the $i^{th}$ sense}) = P(S_i | ``E'')
\end{equation}

Where $S_i$ is the $i^{th}$ sense\footnote{$i^{th}$ disambiguation in Wikipedia parlance} of the entity E. 

\subsection{How often do the 2 entities appear together?}
A second interesting statistic would be to count how many times do two given entities, taking two given senses appear together.
For example, We might want to know how many times does Nokia \url{http://en.wikipedia.org/wiki/Nokia} appears with Gingerbread \url{http://en.wikipedia.org/wiki/Gingerbread_(operating_system)}

We call should counts Entity bi grams. We note that in contrast to word bi-grams and relational grams [\ref{relgram}], entity bi grams
are symmetric, and there is no obvious use case where we might need to know the order dependent occurrence count of the entities. 
However, such a formulation will lead to a sparse distribution, since each count will have to be normalized by the total number of 
entity bigrams. We thus define the entity bi gram count as follows : 
\begin{equation}
 \tag{2}
 \text{Entity Bi Gram}(E2 | E1) = P(E2\text{ follows }E1) = P(E2 | E1) 
\end{equation}

We propose an application of Entity bi grams for finding out important entities motivated by [\ref{relgram}].

\section{Applications}
We list a few applications of the sense prior and outline an application of the entity bigrams.

 \subsection{Sense Prior}
 A prior over the sense will be helpful in many applications related to information retrieval. 
 \begin{itemize}
  \item Entity Querying
  \item Knowledge graph based searching
 \end{itemize}

 \subsection{Entity Bigrams}
 
 Given an entity, we want to find out other important entities that are related to it.
 For example, given an entity \textbf{Barack Obama, President of the USA}, we need to provide top 10 entities that are
 ``close'' to Barack Obama the President. Since the solution is only a slight modification of the solution 
 presented in [\ref{cohschemas}] for finding out important relations, we only sketch an outline here. 
 
For the entity we are interested in, Say X, create a node. Now attach to the node X all the entities E for which
$P(E|X) >  \epsilon$ where $\epsilon$ is some threshold. Let the weight of the edge be defined as

\begin{equation}
\tag{3}
 P(E|X) + P(X|E) 
\end{equation}

We then apply personalized page rank on the X sub graph, starting with X having a 
page rank of 1 and other nodes having a page rank of 0. We can then sort the nodes
based on the their page ranks upon convergence. 
 


\section{Baseline Approach}
How do we collect the aforementioned statistics?
This question shouldn't be too difficult to answer now. The whole of part 3
was dedicated towards tagging entity mentions in the text. We can use any of the 
methods (for example, AIDA can be set up as a rest service) to tag the corpus, and then iterate over the corpus to collect these statistics
in single pass. 
\section{Solution based on estimating class ratios}
While estimating class ratios by doing per mention disambiguation seems pretty intuitive, we are doing more than what we need to do.
Intuitively, we are not interested in what each mention disambiguates to, a count of how many times does a particular entity appears
is the desideratum. Recently, there has been a progress on methods for predicting the class ratio directly, without going through the 
label and collect route. In particular, [\ref{mmd}] discuss a solution based on maximum mean discrepancy and proves some upper bounds 
on errors. 

If mmd really works, we should expect better estimation of the sense prior and the entity grams. The next chapter outlines the mmd based 
solution and how mmd may be used to estimate the sense priors for different entities. 

\chapter{MMD for estimating ratios of named entities in text}

\section{Introduction}

\section{MMD Formulation}
