\section{Distributional Statistics of Named entities}
Once you have a catalog of things, it makes sense to ask which of these ``things'' are more important than the others.
In fact, one might extend the question and ask, ``Which pairs (or triples) of these things appear together on the open web?''.
We define several different statistics one might be interested in over these entity catalogs, discuss some applications, 
propose a baseline method and finally, prepare the ground for the next section by giving an outline of a solution 
which is aimed at directly providing us with the statistics we are looking for. 

\subsection{What Statistics?}

\subsubsection{Which sense dominates for an entity?}
For starters, we might want to calculate the number of times a particular ``sense'' of an entity\footnote{Please note that we 
refer to entity in general terms. For example, any object having a YAGO id is an entity}. 
For example, the ``Gingerbread'' might refer to several different concepts; from perhaps the most famous Android 2.3 to the novel.
We want to know out of all the \emph{Gingerbreads} on the web, how many refer to the Operating system. 
We call this number the sense prior.
\begin{equation}
\tag{1}
\text{Sense Prior}(S_i, E) =  P(E\text{ appears as the $i^{th}$ sense}) = P(S_i | ``E'')
\end{equation}

Where $S_i$ is the $i^{th}$ sense\footnote{$i^{th}$ disambiguation in Wikipedia parlance} of the entity E. 

\subsubsection{How often do the 2 entities appear together?}
A second interesting statistic would be to count how many times do two given entities, taking two given senses appear together.
For example, We might want to know how many times does Nokia \url{http://en.wikipedia.org/wiki/Nokia} appears with Gingerbread \url{http://en.wikipedia.org/wiki/Gingerbread_(operating_system)}

We call should counts Entity bi grams. We note that in contrast to word bi-grams and relational grams [\ref{relgram}], entity bi grams
are symmetric, and there is no obvious use case where we might need to know the order dependent occurrence count of the entities. 
However, such a formulation will lead to a sparse distribution, since each count will have to be normalized by the total number of 
entity bigrams. We thus define the entity bi gram count as follows : 
\begin{equation}
 \tag{2}
 \text{Entity Bi Gram}(E2 | E1) = P(E2\text{ follows }E1) = P(E2 | E1) 
\end{equation}

We propose an application of Entity bi grams for finding out important entities motivated by [\ref{relgram}].

\subsection{Applications}
We list a few applications of the sense prior and outline an application of the entity bigrams.

 \subsubsection{Sense Prior}
 A prior over the sense will be helpful in many applications related to information retrieval. 
 \begin{itemize}
  \item Entity Querying
  \item Knowledge graph based searching
 \end{itemize}

 \subsubsection{Entity Bigrams}
 
 Given an entity, we want to find out other important entities that are related to it.
 For example, given an entity \textbf{Barack Obama, President of the USA}, we need to provide top 10 entities that are
 ``close'' to Barack Obama the President. Since the solution is only a slight modification of the solution 
 presented in [\ref{cohschemas}] for finding out important relations, we only sketch an outline here. 
 
For the entity we are interested in, Say X, create a node. Now attach to the node X all the entities E for which
$P(E|X) >  \epsilon$ where $\epsilon$ is some threshold. Let the weight of the edge be defined as

\begin{equation}
\tag{3}
 P(E|X) + P(X|E) 
\end{equation}

We then apply personalized page rank on the X sub graph, starting with X having a 
page rank of 1 and other nodes having a page rank of 0. We can then sort the nodes
based on the their page ranks upon convergence. 
 


\subsection{Baseline Approach : Label and Collect}
How do we collect the aforementioned statistics?
This question shouldn't be too difficult to answer now. The whole of part 3
was dedicated towards tagging entity mentions in the text. We can use any of the 
methods (for example, AIDA can be set up as a rest service) to tag the corpus, and then iterate over the corpus to collect these statistics
in single pass. 
\subsection{Solution based on estimating class ratios}
While estimating class ratios by doing per mention disambiguation seems pretty intuitive, we are doing more than what we need to do.
We are not interested in what each mention disambiguates to, a count of how many times does a particular entity appears
is the desideratum. There are 3 different methods in the open domain for directly estimating the class ratio[\ref{mmd}] 
, without going through the label and collect route. In particular, [\ref{mmd}] discuss a solution based on maximum mean 
discrepancy and proves some upper bounds on errors. 

If mmd really works, we should expect better estimation of the sense prior and the entity grams. The next section outlines the mmd based 
solution and how mmd may be used to estimate the sense priors for different entities. 

\section{MMD for estimating ratios of named entities in text}
This section discusses the MMD approach for direct estimation of class ratios[\ref{mmd}]. We first provide an intuition for the 
solution, follow it up with some results 
\subsection{Introduction}
The following hypothetical example is aimed to capture the gist of class ratio estimation using mmd.
Suppose that in a factory producing balls, there are 3 different ball production machines, (say) A, B and C.
Since neither of the machines is perfect, they do not produce spherical balls. Rather, the balls are
ellipsoids. Thus, for each ball, we have 3 different features corresponding to the three semi-axes. 
Since all the machines are different, they have their own unique view of how balls should look like, 
and thus we expect that the semi axes are a good way of telling the machine which produced a given ball.

Also assume that for all the 3 machines, we also have the most likely (expected) semi axes measures of the balls produced by them.
Let us call these $\phi_a(x), \phi_b(x),$ and $\phi_c(x)$. These are the \emph{expected feature weights}.

Suppose we are given a 150 balls produced from these three machines. For 120 balls out of them, we know the machine 
from which the ball was produced. For the remaining 30 balls, we are asked to give an estimate of how many balls came 
from machine A, B and C. 

How do we do this? Of course, we can learn a classifier from the 120 known instances and then learn the label each of 
the 30 balls and collect counts (label and collect approach). MMD takes the following route to reach the solution.

Suppose we are magically given the true class ratios, say, $\theta_a$, $\theta_b$ and $\theta_c$. Let  
$\phi$ be the average of the semi axes of the 30 balls. Let $\phi'$ be defined as 
\begin{equation}
 \phi' = \phi_a * \theta_a + \phi_b * \theta_b + \phi_c * \theta_c 
\end{equation}

Clearly, we would expect $\phi$ to match $\phi'$. 

Note that we don't really know the $\theta s$, but all is not lost since we know what to look for; 
we look for the thetas that minimize : 
\begin{equation}
 ||\phi_a * \theta_a + \phi_b * \theta_b + \phi_c * \theta_c  - \phi'||^2
\end{equation}

While ensuring that  :
\begin{itemize}
 \item All the $\theta s$ sum to 1.
 \item All the $\theta s$ are non negative.
\end{itemize}

This is the motivation behind MMD for class ratio estimation.
\subsection{MMD Formulation}

With the above example by our side
\subsubsection{Problem Definition}
We reproduce the problem statement from [\ref{mmd}]
 \begin{itemize}
  \item  Let $X = {x \in R_d }$ be the set of all instances and 
  $Y = {0, 1, . . . , c}$ be the  set of all labels.
 \medskip
\item Given a labeled dataset $D(\subset X\text{ x } Y)$, design an estimator that for any given set
$U (\subset X )$ can estimate the class ratios $\theta = [\theta_0 , \theta_1 , . . . , \theta_c ]$
Where  $\theta_y$ denotes the fraction of instances with class label y in U 
 \end{itemize}

\subsubsection{Objective}
\begin{itemize}
  \item Match two distributions based on the mean of features in the hilbert space induced by a kernel K. \medskip
  \item Assume that distribution of features is same in both training and test data
    $P_U (x|y) = P_D (x|y), \forall y \in Y$ \medskip
  \item Thus, the test distribution must equal $Q(x) = \Sigma_{y} P_D (x|y)\theta_y$  \medskip
 \end{itemize}
 
 \begin{itemize}
  \item Let $\bar{\phi}_y$ and $\bar{\phi}_u$ denote the true means of the feature vectors of the y th class and the
unlabeled data \medskip
  \item Suppose we somehow get the true class ratios ${\theta}$. The true mean of the feature vector of the
  unlabeled data can then be obtained by $\Sigma_y\theta_y\bar{\phi}_y$. \medskip
  \item So ideally, $\Sigma_y\theta_y\bar{\phi}_y = \bar{\phi}_u$ \medskip
 \end{itemize}
 The objective thus is
  \begin{equation}
  \argmin{\theta}\Sigma_y{ \in Y\text{  } }|| \Sigma_y\theta_y\bar{\phi}_y - \bar{\phi}_u || ^ {2}  
  \end{equation}
  \begin{center}
  Such that 
  \begin{itemize}
   \item \begin{center} $\forall y, \theta_y \geq 0$ \end{center}
  \item \begin{center} $\sum_{y = 0}^c \theta_y = 1$ \end{center} 
  \end{itemize}
  \end{center}
  

Interesting discussion on theoretical bounds on the error in the class ratios thus predicted and
methods for learning Kernel can be found in [\ref{mmd}]

\subsubsection{Estimating entity ratios using MMD}
Given a corpus with mentions identified (using, say [\ref{stanfordner}]), we want
reliable estimates of frequency of each of the entities. In this subsection, we gloss over the solution.
\begin{itemize}
\item \textbf{Features}  \\ Each mention has several candidate disambiguations. This gives one way of 
formulating the features. For each mention, we can have a (sparse) feature vector having non zero scores
for the candidates.
\item \textbf{Training data} \\ Can be obtained by splicing the named entity disambiguation pipeline of 
any of the popular named entity disambiguators. [\ref{aidafeature}] discusses how to achieve this for AIDA,
a popular named entity disambiguator. 
\end{itemize}




